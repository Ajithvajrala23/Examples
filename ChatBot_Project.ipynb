{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n",
      "(88, 1)\n",
      "(46, 1)\n",
      "(98, 1)\n",
      "(194, 1)\n",
      "(48, 1)\n"
     ]
    }
   ],
   "source": [
    "Aegis_Domain= pd.read_csv(r\"E:\\Aegis\\Project\\Data_set\\rechatterbotpdf/1.csv\")\n",
    "Data_Mining_General=pd.read_csv(r\"E:\\Aegis\\Project\\Data_set/Data_Mining_General.csv\")\n",
    "Pythom_R_ML=pd.read_csv(r\"E:\\Aegis\\Project\\Data_set/Pythom_R_ML.csv\")\n",
    "Statistics=pd.read_csv(r\"E:\\Aegis\\Project\\Data_set/Statistics.csv\")\n",
    "Hadoop=pd.read_csv(r\"E:\\Aegis\\Project\\Data_set/Hadoop.csv\")\n",
    "Visualization=pd.read_csv(\"E:\\Aegis\\Project\\Data_set/Visualization.csv\")\n",
    "##\n",
    "#Size of each data set\n",
    "print(Aegis_Domain.shape)\n",
    "print(Data_Mining_General.shape)\n",
    "print(Pythom_R_ML.shape)\n",
    "print(Statistics.shape)\n",
    "print(Hadoop.shape)\n",
    "print(Visualization.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pre processing the data\n",
    "import re\n",
    "def cleaning_text(review):\n",
    "    cleaned =re.sub(\"[^a-zA-Z/:.?]\", \" \",review)\n",
    "    words =cleaned.lower().split()\n",
    "    return(\" \".join( words ))\n",
    "new_words=[]\n",
    "for i in range(0,Aegis_Domain.size -1 ):\n",
    "    new_words.append(cleaning_text(Aegis_Domain[\"QA\"][i]))\n",
    "for i in range(0,Data_Mining_General.size -1 ):\n",
    "    new_words.append(cleaning_text(Data_Mining_General[\"QA\"][i]))\n",
    "for i in range(0,Pythom_R_ML.size -1):\n",
    "    new_words.append(cleaning_text(Pythom_R_ML[\"QA\"][i]))\n",
    "for i in range(0,Statistics.size -1):\n",
    "    new_words.append(cleaning_text(Statistics[\"QA\"][i]))\n",
    "for i in range(0,Hadoop.size -1):\n",
    "    new_words.append(cleaning_text(Hadoop[\"QA\"][i]))\n",
    "for i in range(0,Visualization.size - 1):\n",
    "    new_words.append(cleaning_text(Visualization[\"QA\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ajith Vajrala\\Anaconda2\\lib\\site-packages\\chatterbot\\storage\\jsonfile.py:30: UnsuitableForProductionWarning: The JsonFileStorageAdapter is not recommended for production environments.\n",
      "  self.UnsuitableForProductionWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Ajith\n",
      "[nltk_data]     Vajrala\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Ajith\n",
      "[nltk_data]     Vajrala\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Ajith\n",
      "[nltk_data]     Vajrala\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Ajith\n",
      "[nltk_data]     Vajrala\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from chatterbot import ChatBot\n",
    "from chatterbot.trainers import ChatterBotCorpusTrainer\n",
    "#\n",
    "#Import logic adapters for basic operations\n",
    "#\n",
    "chatbot=ChatBot(\"Example1\")\n",
    "#\n",
    "#Import List trainer for training the chat history\n",
    "#\n",
    "from chatterbot.trainers import ListTrainer\n",
    "#\n",
    "#Move the preprocessed chat history to conversations\n",
    "#\n",
    "conversation=new_words\n",
    "chatbot.set_trainer(ListTrainer)\n",
    "#\n",
    "#training the conversation\n",
    "#\n",
    "chatbot.train(conversation)\n",
    "#\n",
    "#Import corpus.english for basic greetings and casual replies\n",
    "#\n",
    "chatbot.train(\"chatterbot.corpus.english\")\n",
    "chatbot.set_trainer(ChatterBotCorpusTrainer)\n",
    "#chatbot.train(\"chatterbot.corpus.english\")\n",
    "chatbot.train(\n",
    "    \"chatterbot.corpus.english.greetings\",\n",
    "    \"chatterbot.corpus.english.conversations\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the wholesome study of the huge data by using various big data and analytics tools is called business analytics.\n",
      "it means extracting knowledge from the data by using various machine learning and statistical techniques.\n",
      "this program is delivered at centre for excellence in telecom technology and management cettm mtnl s world class campus with state of art ibm business analytics lab and ibm cloud computing lab at powai in mumbai.\n",
      "yes aegis has a tie up with hdfc credila for education loan.\n",
      "check about aegis at www.aegis.edu.in and www.bellaward.com\n",
      "Could I borrow a cup of sugar?\n",
      "I am doing well, how about you?\n",
      "hadoop is an open source framework that allows to store and process big data in a distributed environment across clusters of computers using simple programming models. it is designed to scale up from single servers to thousands of machines each offering local computation and storage. this brief tutorial provides a quick introduction to big data mapreduce algorithm and hadoop distributed file system.\n",
      "A man in a mask.\n",
      "nas runs on a single machine and thus there is no probability of data redundancy whereas hdfs runs on a cluster of different machines thus there is data redundancy because of the replication protocol. nas stores data on a dedicated hardware whereas in hdfs all the data blocks are distributed across local drives of the machines. in nas data is stored independent of the computation and hence hadoop mapreduce cannot be used for processing whereas hdfs works with hadoop mapreduce as the computations in hdfs are moved to data.\n",
      "using sophisticated statistical techniques and software data mining is the search for significant patterns and trends in large databases. this provides information crucial to helping businesses and industries improve products marketing sales and customer service. with a ccsu master s degree in data mining you ll be in high demand as employers look for experts to make sense of ever increasing mountains of information.\n",
      "it means extracting knowledge from the data by using various machine learning and statistical techniques.\n"
     ]
    }
   ],
   "source": [
    "#Give the input and get the response from the chat bot\n",
    "#\n",
    "print chatbot.get_response(\"Tell me about business Analytics?\")\n",
    "print chatbot.get_response(\"what exactly data science is?\")\n",
    "print chatbot.get_response(\"where is campus\")\n",
    "print chatbot.get_response(\"can i get a study loan\")\n",
    "print chatbot.get_response(\"What is Aegis\")\n",
    "print chatbot.get_response(\"what is your name?\")\n",
    "print chatbot.get_response(\"good morning\")\n",
    "print chatbot.get_response(\"What is Hadoop?\")\n",
    "print chatbot.get_response(\"What are course timings?\")\n",
    "print chatbot.get_response(\"where is difference between python and R?\")\n",
    "print chatbot.get_response(\"what is data mining?\")\n",
    "print chatbot.get_response(\"what is data science?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
